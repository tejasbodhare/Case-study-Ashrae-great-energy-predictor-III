{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "umDGBSN0001d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import datetime as dt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "import gc\n",
        "from numpy import percentile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import preprocessing\n",
        "import pickle\n",
        "import lightgbm as lgb\n",
        "from zipfile import ZipFile\n",
        "from IPython.display import clear_output\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting all the files\n",
        "with ZipFile('/content/drive/MyDrive/ashrae-energy-prediction.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('energy_prediction')"
      ],
      "metadata": {
        "id": "qefyoENcHqSm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the csv files into dataframe\n",
        "test=pd.read_csv('/content/energy_prediction/train.csv')\n",
        "building_metadata=pd.read_csv('/content/energy_prediction/building_metadata.csv')\n",
        "weather_test=pd.read_csv('/content/energy_prediction/weather_train.csv')"
      ],
      "metadata": {
        "id": "2mUQPGnPH7Lo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the trained lgbm model\n",
        "with open('/content/drive/MyDrive/lgbm_model.pkl','rb') as f:\n",
        "  lgbm_model=pickle.load(f)"
      ],
      "metadata": {
        "id": "iZPfCKL8IJex"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' This function takes three dataframes as arguments and returns predictions for the test data '''\n",
        "\n",
        "def final_func_1(test,building_metadata,weather_test):  \n",
        "\n",
        "\n",
        "  def time_alignment(df):\n",
        "    ''' This function aligns the timestamp '''\n",
        "\n",
        "    temp_df=df[['site_id','timestamp','air_temperature']]\n",
        "\n",
        "    # calculate ranks of hourly temperatures within date/site_id chunks\n",
        "    temp_df['temp_rank']=temp_df.groupby(['site_id', temp_df.timestamp.dt.date],)['air_temperature'].rank('average')\n",
        "\n",
        "    # create 2D dataframe of site_ids (0-16) x mean hour rank of temperature within day (0-23)\n",
        "    df_2d=temp_df.groupby(['site_id', temp_df.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n",
        "\n",
        "    # align scale, so each value within row is in [0,1] range\n",
        "    df_2d = df_2d / df_2d.max(axis=1).values.reshape((-1,1))\n",
        "\n",
        "    # assuming site ids (1,5,12) has the most correct temp peaks at 14:00\n",
        "    site_ids_offsets= pd.Series(df_2d.values.argmax(axis=1) - 14)\n",
        "\n",
        "    temp_df['offset'] = temp_df.site_id.map(site_ids_offsets)\n",
        "\n",
        "    # add offset\n",
        "    temp_df['timestamp_aligned'] = (temp_df.timestamp - pd.to_timedelta(temp_df.offset, unit='H'))\n",
        "  \n",
        "    # replace the timestamp with aligned timestamps in the original dataframe\n",
        "    df['timestamp']=temp_df['timestamp_aligned']\n",
        "\n",
        "    return df \n",
        "\n",
        "  #merging test and building_metadata\n",
        "  merge_df=building_metadata.merge(test,on='building_id',how='right')\n",
        "  \n",
        "  #converting timestamp to datetime format\n",
        "  weather_test['timestamp']= pd.to_datetime(weather_test['timestamp'],infer_datetime_format=True)\n",
        "  merge_df['timestamp']=pd.to_datetime(merge_df['timestamp'],infer_datetime_format=True)\n",
        "  \n",
        "  weather_test=time_alignment(weather_test)\n",
        "  \n",
        "  #merging waether_test and merge_df\n",
        "  merge_df=merge_df.merge(weather_test,on=['site_id','timestamp'],how='left')\n",
        "\n",
        "  #removing features with high nan values and unimportant features\n",
        "  merge_df=merge_df.drop(['cloud_coverage','precip_depth_1_hr','floor_count','year_built','site_id','wind_direction','sea_level_pressure','row_id'],axis=1)\n",
        "\n",
        "  #converting square_feet to log values\n",
        "  merge_df['square_feet'] = np.log1p(merge_df['square_feet'])\n",
        "\n",
        "\n",
        "  # adding month, day, and hour feature\n",
        "  merge_df['Month']=pd.DatetimeIndex(merge_df['timestamp']).month\n",
        "  merge_df['Day']=pd.DatetimeIndex(merge_df['timestamp']).day\n",
        "  merge_df['Hour']=pd.DatetimeIndex(merge_df['timestamp']).hour\n",
        "\n",
        "  #one hot encoding primary_use feature\n",
        "  merge_df=pd.get_dummies(merge_df, columns=['primary_use'])\n",
        "\n",
        "  #adding dayofweek and season\n",
        "  merge_df[\"day_of_week\"]=np.uint8(merge_df['timestamp'].dt.dayofweek)\n",
        "  merge_df['season']= merge_df['Month'].apply(lambda x: 'Spring' if x==3 or x==4 or x==5 else 'Summer' if \n",
        "                                                x==6 or x==7 or x==8 \n",
        "                                                else 'Autumn' if x==9 or x==10 or \n",
        "                                                x==11 else 'Winter')\n",
        "  \n",
        "  # one hot encoding season feature\n",
        "  merge_df=pd.get_dummies(merge_df, columns=['season'])\n",
        "\n",
        "  merge_df=merge_df.drop(['timestamp'],axis=1)\n",
        "\n",
        "  #predicting test data\n",
        "  test_pred=np.round(lgbm_model.predict(merge_df),4)\n",
        "\n",
        "  return list(test_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "0IErIXJu4w33"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' This function takes three dataframes and target variable as arguments and returns RMSLE '''\n",
        "\n",
        "def final_func_2(test,building_metadata,weather_test,y_actual): \n",
        "\n",
        "\n",
        "  def time_alignment(df):\n",
        "    ''' This function aligns the timestamp '''\n",
        "\n",
        "    temp_df=df[['site_id','timestamp','air_temperature']]\n",
        "\n",
        "    # calculate ranks of hourly temperatures within date/site_id chunks\n",
        "    temp_df['temp_rank']=temp_df.groupby(['site_id', temp_df.timestamp.dt.date],)['air_temperature'].rank('average')\n",
        "\n",
        "    # create 2D dataframe of site_ids (0-16) x mean hour rank of temperature within day (0-23)\n",
        "    df_2d=temp_df.groupby(['site_id', temp_df.timestamp.dt.hour])['temp_rank'].mean().unstack(level=1)\n",
        "\n",
        "    # align scale, so each value within row is in [0,1] range\n",
        "    df_2d = df_2d / df_2d.max(axis=1).values.reshape((-1,1))\n",
        "\n",
        "    # assuming site ids (1,5,12) has the most correct temp peaks at 14:00\n",
        "    site_ids_offsets= pd.Series(df_2d.values.argmax(axis=1) - 14)\n",
        "\n",
        "    temp_df['offset'] = temp_df.site_id.map(site_ids_offsets)\n",
        "\n",
        "    # add offset\n",
        "    temp_df['timestamp_aligned'] = (temp_df.timestamp - pd.to_timedelta(temp_df.offset, unit='H'))\n",
        "  \n",
        "    # replace the timestamp with aligned timestamps in the original dataframe\n",
        "    df['timestamp']=temp_df['timestamp_aligned']\n",
        "\n",
        "    return df \n",
        "\n",
        "  #merging test and building_metadata\n",
        "  merge_df=building_metadata.merge(test,on='building_id',how='right')\n",
        "  \n",
        "  #converting timestamp to datetime format\n",
        "  weather_test['timestamp']= pd.to_datetime(weather_test['timestamp'],infer_datetime_format=True)\n",
        "  merge_df['timestamp']=pd.to_datetime(merge_df['timestamp'],infer_datetime_format=True)\n",
        "  \n",
        "  weather_test=time_alignment(weather_test)\n",
        "  \n",
        "  #merging waether_test and merge_df\n",
        "  merge_df=merge_df.merge(weather_test,on=['site_id','timestamp'],how='left')\n",
        "\n",
        "  #removing features with high nan values and unimportant features\n",
        "  merge_df=merge_df.drop(['cloud_coverage','precip_depth_1_hr','floor_count','year_built','site_id','wind_direction','sea_level_pressure','row_id'],axis=1)\n",
        "\n",
        "  #converting square_feet to log values\n",
        "  merge_df['square_feet'] = np.log1p(merge_df['square_feet'])\n",
        "\n",
        "\n",
        "  # adding month, day, and hour feature\n",
        "  merge_df['Month']=pd.DatetimeIndex(merge_df['timestamp']).month\n",
        "  merge_df['Day']=pd.DatetimeIndex(merge_df['timestamp']).day\n",
        "  merge_df['Hour']=pd.DatetimeIndex(merge_df['timestamp']).hour\n",
        "\n",
        "  #one hot encoding primary_use feature\n",
        "  merge_df=pd.get_dummies(merge_df, columns=['primary_use'])\n",
        "\n",
        "  #adding dayofweek and season\n",
        "  merge_df[\"day_of_week\"]=np.uint8(merge_df['timestamp'].dt.dayofweek)\n",
        "  merge_df['season']= merge_df['Month'].apply(lambda x: 'Spring' if x==3 or x==4 or x==5 else 'Summer' if \n",
        "                                                x==6 or x==7 or x==8 \n",
        "                                                else 'Autumn' if x==9 or x==10 or \n",
        "                                                x==11 else 'Winter')\n",
        "  \n",
        "  # one hot encoding season feature\n",
        "  merge_df=pd.get_dummies(merge_df, columns=['season'])\n",
        "\n",
        "  merge_df=merge_df.drop(['timestamp'],axis=1)\n",
        " \n",
        "  #predicting test data \n",
        "  test_pred=lgbm_model.predict(merge_df)\n",
        "  test_pred=np.round(test_pred,4)\n",
        "    \n",
        "  #converting target variable to logarithmic values\n",
        "  y_act=np.round(np.log1p(y_actual),4)\n",
        "   \n",
        "  #getting RMSLE score\n",
        "  RMSLE=MSE(y_act,test_pred,squared=False)\n",
        "\n",
        "  return RMSLE\n"
      ],
      "metadata": {
        "id": "Md3bCXkwYkgD"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}