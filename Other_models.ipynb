{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pm2ZvnszbGcZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "import gc\n",
    "from numpy import percentile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4N70WfRqi2F4"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    '''This function reduces the size of  dataframe '''\n",
    "    \n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pj8_wwDbIQa"
   },
   "source": [
    "# Linear regression(label encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_R7-e29LbU3l"
   },
   "outputs": [],
   "source": [
    "#loading dataframes\n",
    "with open(\"/content/drive/MyDrive/cleaned_df.pkl\",\"rb\") as f:\n",
    "  cleaned_df=pickle.load(f)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Featured_df.pkl\",\"rb\") as f:\n",
    "  Featured_df=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCEmjCy8nvmb"
   },
   "outputs": [],
   "source": [
    "# removing one hot encoded primary_use feature\n",
    "l1=[]\n",
    "for col in Featured_df.columns:\n",
    "  if col.startswith(\"primary\"):\n",
    "    l1.append(col)\n",
    "\n",
    "Featured_df=Featured_df.drop(l1,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qvmhGiujwxt"
   },
   "outputs": [],
   "source": [
    "#label encoding primary_use feature\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "Featured_df['primary_use']= label_encoder.fit_transform(cleaned_df['primary_use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MI9KJRktt-4t"
   },
   "outputs": [],
   "source": [
    "y=Featured_df.meter_reading\n",
    "X=Featured_df.drop('meter_reading',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4gETbHtuCE2",
    "outputId": "35351956-961f-4fe8-dc93-359a514bf5c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "790"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Featured_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_x-y_QiuPNo"
   },
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "del X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apLNuG0kudlp",
    "outputId": "d9b30e0d-c520-4792-9b18-473aab865938"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training linear regression model\n",
    "model=LinearRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcryWBI2u7aC",
    "outputId": "2823e336-814a-46b9-a11f-0359c71ca12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of train data: 1.6757702209110554\n",
      "RMSE of test data: 1.6774855671483084\n"
     ]
    }
   ],
   "source": [
    "#predicting test data and train data\n",
    "y_predict_test=model.predict(X_test)\n",
    "y_predict_train=model.predict(X_train)\n",
    "\n",
    "#root mean squared error of test data and train data\n",
    "print(\"RMSE of train data:\",MSE(y_train,y_predict_train,squared=False))\n",
    "print(\"RMSE of test data:\",MSE(y_test,y_predict_test,squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPoYj6cfhdx8"
   },
   "source": [
    "Linear regression with label encoding is performing slightly worst than linear regression with one hot encoding. Hence we will use one hot encoding for all other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbEnY9i7s7Ba"
   },
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o03UVX63bU-W"
   },
   "outputs": [],
   "source": [
    "#loading dataframe\n",
    "with open(\"/content/drive/MyDrive/Featured_df.pkl\",\"rb\") as f:\n",
    "  Featured_df=pickle.load(f)\n",
    "\n",
    "y=Featured_df.meter_reading\n",
    "X=Featured_df.drop('meter_reading',axis=1)\n",
    "\n",
    "del Featured_df\n",
    "gc.collect()\n",
    "\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "waQHp_s-bpKi",
    "outputId": "36904047-cfca-4163-a59b-8c973bef5fd4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bfcb3b94-8514-46cd-bc3b-b2ca0a5cdc35\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.380704</td>\n",
       "      <td>0.857357</td>\n",
       "      <td>3.989043</td>\n",
       "      <td>0.074130</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 25}</td>\n",
       "      <td>-0.642098</td>\n",
       "      <td>-0.645421</td>\n",
       "      <td>-0.648611</td>\n",
       "      <td>-0.645377</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.381253</td>\n",
       "      <td>-0.407494</td>\n",
       "      <td>-0.412130</td>\n",
       "      <td>-0.400292</td>\n",
       "      <td>0.013595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.317555</td>\n",
       "      <td>7.053305</td>\n",
       "      <td>7.350448</td>\n",
       "      <td>0.566913</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 30}</td>\n",
       "      <td>-0.650094</td>\n",
       "      <td>-0.643975</td>\n",
       "      <td>-0.645567</td>\n",
       "      <td>-0.646545</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.203373</td>\n",
       "      <td>-0.237119</td>\n",
       "      <td>-0.238295</td>\n",
       "      <td>-0.226262</td>\n",
       "      <td>0.016193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>187.832401</td>\n",
       "      <td>0.887840</td>\n",
       "      <td>8.807534</td>\n",
       "      <td>0.703918</td>\n",
       "      <td>35</td>\n",
       "      <td>{'max_depth': 35}</td>\n",
       "      <td>-0.660738</td>\n",
       "      <td>-0.656569</td>\n",
       "      <td>-0.656952</td>\n",
       "      <td>-0.658086</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.101205</td>\n",
       "      <td>-0.128482</td>\n",
       "      <td>-0.129042</td>\n",
       "      <td>-0.119576</td>\n",
       "      <td>0.012992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185.203277</td>\n",
       "      <td>2.849498</td>\n",
       "      <td>8.059208</td>\n",
       "      <td>0.129561</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_depth': 40}</td>\n",
       "      <td>-0.664950</td>\n",
       "      <td>-0.663480</td>\n",
       "      <td>-0.662534</td>\n",
       "      <td>-0.663655</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.043686</td>\n",
       "      <td>-0.062212</td>\n",
       "      <td>-0.064032</td>\n",
       "      <td>-0.056643</td>\n",
       "      <td>0.009192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfcb3b94-8514-46cd-bc3b-b2ca0a5cdc35')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bfcb3b94-8514-46cd-bc3b-b2ca0a5cdc35 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bfcb3b94-8514-46cd-bc3b-b2ca0a5cdc35');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     150.380704      0.857357         3.989043        0.074130   \n",
       "1     175.317555      7.053305         7.350448        0.566913   \n",
       "2     187.832401      0.887840         8.807534        0.703918   \n",
       "3     185.203277      2.849498         8.059208        0.129561   \n",
       "\n",
       "  param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0              25  {'max_depth': 25}          -0.642098          -0.645421   \n",
       "1              30  {'max_depth': 30}          -0.650094          -0.643975   \n",
       "2              35  {'max_depth': 35}          -0.660738          -0.656569   \n",
       "3              40  {'max_depth': 40}          -0.664950          -0.663480   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0          -0.648611        -0.645377        0.002659                1   \n",
       "1          -0.645567        -0.646545        0.002592                2   \n",
       "2          -0.656952        -0.658086        0.001881                3   \n",
       "3          -0.662534        -0.663655        0.000994                4   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0           -0.381253           -0.407494           -0.412130   \n",
       "1           -0.203373           -0.237119           -0.238295   \n",
       "2           -0.101205           -0.128482           -0.129042   \n",
       "3           -0.043686           -0.062212           -0.064032   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0         -0.400292         0.013595  \n",
       "1         -0.226262         0.016193  \n",
       "2         -0.119576         0.012992  \n",
       "3         -0.056643         0.009192  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "params={'max_depth':[25,30,35,40]}\n",
    "clf=RandomizedSearchCV(DecisionTreeRegressor(random_state=0),params,scoring='neg_root_mean_squared_error',\n",
    "                       cv=3,random_state=0,return_train_score=True)\n",
    "clf.fit(X_train,y_train)\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUtr9udD0Q2e"
   },
   "source": [
    "from above table we can see that max_depth=25 is the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiJUA3DQBYDx",
    "outputId": "f7be2d6d-90a9-47cf-f179-b7eebd7718b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of train data: 0.42514026089113566\n",
      "RMSE of test data: 0.611504709817372\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Decision tree with max_depth=25\n",
    "model=DecisionTreeRegressor(random_state=0,max_depth=25)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#predicting test data and train data\n",
    "y_predict_test=model.predict(X_test)\n",
    "y_predict_train=model.predict(X_train)\n",
    "\n",
    "#root mean squared error of test data and train data\n",
    "print(\"RMSE of train data:\",MSE(y_train,y_predict_train,squared=False))\n",
    "print(\"RMSE of test data:\",MSE(y_test,y_predict_test,squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bBZW0X3H1hS"
   },
   "source": [
    "Thus with decision tree we are getting RMSE value for test data= 0.6115. This is better than our baseline model(linear regression + OHE) RMSE=1.6662 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eak7OC4Jrw5R"
   },
   "source": [
    "# LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fts_Zf-myrk4"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Featured_df.pkl\",\"rb\") as f:\n",
    "  Featured_df=pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ubx32qK0Mbu"
   },
   "outputs": [],
   "source": [
    "y=Featured_df.meter_reading\n",
    "X=Featured_df.drop('meter_reading',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfE9MSAn0Rjj",
    "outputId": "7f0787da-222d-474b-91b6-461d4e75dcb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "del X,y\n",
    "del Featured_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzcAyFhpxe7i",
    "outputId": "e86b43f8-d8d5-4f0f-a9e4-4afe98546554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of train data: 0.48297907432123144\n",
      "RMSE of test data: 0.5707418104775989\n"
     ]
    }
   ],
   "source": [
    "'''Here, as i didn't have enough computaional power i didn't use randomizedSearchCV. I have manually tried different sets of parameters \n",
    "   and shown the code for only best parametrs '''\n",
    "\n",
    "model = lgb.LGBMRegressor(max_depth=16,n_estimators=1300,random_state=0,n_jobs=-1,num_leaves=200,learning_rate=1)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#predicting test data and train data\n",
    "y_predict_test=model.predict(X_test)\n",
    "y_predict_train=model.predict(X_train)\n",
    "\n",
    "#root mean squared error of test data \n",
    "print(\"RMSE of train data:\",MSE(y_train,y_predict_train,squared=False))\n",
    "print(\"RMSE of test data:\",MSE(y_test,y_predict_test,squared=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc5iEgkJrDHj"
   },
   "source": [
    "LGBM is the best model till now with test data RMSE=0.5707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SeaHLcKFavW-",
    "outputId": "204b3413-d1fc-4a06-f057-4f382e09469d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del Featured_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-Vo32iENpf4"
   },
   "source": [
    "# LGBM with day_of_week and season feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjmNaNEjPNqb"
   },
   "outputs": [],
   "source": [
    "#adding day_of_week feature\n",
    "Featured_df[\"day_of_week\"]=np.uint8(cleaned_df['timestamp'].dt.dayofweek)\n",
    "\n",
    "# adding season feature\n",
    "Featured_df['season']= Featured_df['Month'].apply(lambda x: 'Spring' if x==3 or x==4 or x==5 else 'Summer' if \n",
    "                                                x==6 or x==7 or x==8 \n",
    "                                                else 'Autumn' if x==9 or x==10 or \n",
    "                                                x==11 else 'Winter')\n",
    "# one hot encoding season feature\n",
    "Featured_df=pd.get_dummies(Featured_df, columns=['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rW0_ZtROlRy",
    "outputId": "d5b9dee0-2020-43e8-e699-535c4d1733ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 618.64 Mb (43.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "#reducing size\n",
    "Featured_df=reduce_mem_usage(Featured_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-B2E0ZdIQ4ro"
   },
   "outputs": [],
   "source": [
    "y=Featured_df.meter_reading\n",
    "X=Featured_df.drop('meter_reading',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9RC7jkp8Q6Sm",
    "outputId": "97159a90-c81f-4926-e055-b7ddf4b9102c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "del X,y,cleaned_df\n",
    "del Featured_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOfX1L0yQKMW",
    "outputId": "dfde1f2e-18d5-46d6-c286-bc0287848123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of train data: 0.4680493259186183\n",
      "RMSE of test data: 0.5568587537669808\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "model = lgb.LGBMRegressor(max_depth=16,n_estimators=1300,random_state=0,n_jobs=-1,num_leaves=200,learning_rate=1)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#predicting test data and train data\n",
    "y_predict_test=model.predict(X_test)\n",
    "y_predict_train=model.predict(X_train)\n",
    "\n",
    "#root mean squared error of test data \n",
    "print(\"RMSE of train data:\",MSE(y_train,y_predict_train,squared=False))\n",
    "print(\"RMSE of test data:\",MSE(y_test,y_predict_test,squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymvZXcqtaqnX"
   },
   "source": [
    "After adding day of week and season feature lgbm model's rmse value for test data is decreased from 0.5707 to 0.5568."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bPHqfwNADsH"
   },
   "source": [
    "# Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoMTuIeuALlq",
    "outputId": "6e45ccaa-6bdf-45cc-affe-c0046cb2b12f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+------------+-----------+\n",
      "|                  Model                  | Train RMSE | Test RMSE |\n",
      "+-----------------------------------------+------------+-----------+\n",
      "|   Linear regression with outliers(OHE)  |   1.8567   |   1.8573  |\n",
      "| Linear regression without outliers(OHE) |   1.6645   |   1.6663  |\n",
      "|    Linear regression(label encoding)    |   1.6758   |   1.6775  |\n",
      "|            Decision Tree(OHE)           |   0.4251   |   0.6115  |\n",
      "|              LightGBM(OHE)              |   0.4829   |   0.5707  |\n",
      "|     LightGBM with Weekday and season    |   0.468    |   0.5568  |\n",
      "+-----------------------------------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "x = PrettyTable()\n",
    "x.field_names=['Model','Train RMSE', 'Test RMSE']\n",
    "x.add_row(['Linear regression with outliers(OHE)',1.8567,1.8573])\n",
    "x.add_row(['Linear regression without outliers(OHE)',1.6645,1.6663])\n",
    "x.add_row(['Linear regression(label encoding)',1.6758,1.6775])\n",
    "x.add_row(['Decision Tree(OHE)',0.4251,0.6115])\n",
    "x.add_row(['LightGBM(OHE)',0.4829,0.5707])\n",
    "x.add_row(['LightGBM with Weekday and season', 0.4680,0.5568])\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4Pj8_wwDbIQa",
    "yaO-MKQRFg4B"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
